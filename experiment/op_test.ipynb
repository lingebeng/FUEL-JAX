{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jax.lax as lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sanity_is_finite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lax.is_finite(jnp.array([1, 2, 3, 4], dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sort_mapping_case",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.lax.sort mapping check passed\n"
     ]
    }
   ],
   "source": [
    "# jax.lax.sort vs torch.ops.aten.sort.default\n",
    "x_np = np.array([[3.0, -1.0, 2.5, 2.5], [0.0, -4.2, 8.1, 1.1]], dtype=np.float32)\n",
    "x_jax = jnp.array(x_np)\n",
    "x_torch = torch.tensor(x_np)\n",
    "\n",
    "# Test ascending sort on last dimension\n",
    "jax_sorted_last = np.array(lax.sort(x_jax, dimension=-1))\n",
    "torch_sorted_last, _ = torch.ops.aten.sort.default(x_torch, dim=-1, descending=False)\n",
    "np.testing.assert_allclose(\n",
    "    jax_sorted_last, torch_sorted_last.numpy(), rtol=0.0, atol=0.0\n",
    ")\n",
    "\n",
    "# Test sort on a non-last dimension\n",
    "jax_sorted_dim0 = np.array(lax.sort(x_jax, dimension=0))\n",
    "torch_sorted_dim0, _ = torch.ops.aten.sort.default(x_torch, dim=0, descending=False)\n",
    "np.testing.assert_allclose(\n",
    "    jax_sorted_dim0, torch_sorted_dim0.numpy(), rtol=0.0, atol=0.0\n",
    ")\n",
    "\n",
    "print(\"jax.lax.sort mapping check passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scatter_mul_mapping_case",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.lax.scatter_mul mapping check passed\n"
     ]
    }
   ],
   "source": [
    "# jax.lax.scatter_mul vs torch.ops.aten.scatter_reduce_.two (reduce='prod')\n",
    "operand_np = np.array([2.0, 3.0, 4.0, 5.0], dtype=np.float32)\n",
    "indices_np = np.array([[1], [3], [1]], dtype=np.int32)\n",
    "updates_np = np.array([10.0, 2.0, 0.5], dtype=np.float32)\n",
    "\n",
    "operand_jax = jnp.array(operand_np)\n",
    "indices_jax = jnp.array(indices_np)\n",
    "updates_jax = jnp.array(updates_np)\n",
    "dnums = lax.ScatterDimensionNumbers(\n",
    "    update_window_dims=(),\n",
    "    inserted_window_dims=(0,),\n",
    "    scatter_dims_to_operand_dims=(0,),\n",
    ")\n",
    "out_jax = np.array(lax.scatter_mul(operand_jax, indices_jax, updates_jax, dnums))\n",
    "\n",
    "operand_torch = torch.tensor(operand_np)\n",
    "index_torch = torch.tensor(indices_np.squeeze(-1), dtype=torch.long)\n",
    "updates_torch = torch.tensor(updates_np)\n",
    "out_torch = operand_torch.clone()\n",
    "torch.ops.aten.scatter_reduce_.two(\n",
    "    out_torch, 0, index_torch, updates_torch, \"prod\", include_self=True\n",
    ")\n",
    "\n",
    "np.testing.assert_allclose(out_jax, out_torch.numpy(), rtol=0.0, atol=0.0)\n",
    "print(\"jax.lax.scatter_mul mapping check passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a63dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: [-5.  -1.   0.5  3.  10. ]\n",
      "输出: [-2.  -1.   0.5  2.   2. ]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "# 1. 准备数据\n",
    "x = jnp.array([-5.0, -1.0, 0.5, 3.0, 10.0])\n",
    "\n",
    "# 2. 调用 lax.clamp\n",
    "# 语义：把 x 限制在 [-2.0, 2.0] 之间\n",
    "# 参数顺序：(最小值, 输入数据, 最大值)\n",
    "result = lax.clamp(-2.0, x, 2.0)\n",
    "\n",
    "print(f\"输入: {x}\")\n",
    "print(f\"输出: {result}\")\n",
    "\n",
    "# 输出预期:\n",
    "# [-2.0, -1.0, 0.5, 2.0, 2.0]\n",
    "# (-5 变成了 -2, 10 变成了 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997bef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.lax.lax.sort(operand: 'Array | Sequence[Array]', dimension: 'int' = -1, is_stable: 'bool' = True, num_keys: 'int' = 1) -> 'Array | tuple[Array, ...]'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.lax.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fd6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70bb43f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5]), tensor([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "torch.ops.aten.sort.default(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f50052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.lax.lax.dot_general(lhs: 'ArrayLike', rhs: 'ArrayLike', dimension_numbers: 'DotDimensionNumbers', precision: 'PrecisionLike' = None, preferred_element_type: 'DTypeLike | None' = None, *, out_sharding=None) -> 'Array'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.dot_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c406ea62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.lax.lax.batch_matmul(lhs: 'Array', rhs: 'Array', precision: 'PrecisionLike' = None) -> 'Array'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.dot\n",
    "jax.lax.dot_general\n",
    "jax.lax.dot_general_p\n",
    "jax.lax.batch_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26df9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.matmul>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c38c10e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PjitFunction of <function matmul at 0x133cf1120>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "449efae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax.lax.cbrt(x: 'ArrayLike', accuracy=None) -> 'Array'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.cbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25329091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0., 1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.iota(jnp.float32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e00e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.lax.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a43c3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_x = jnp.arange(24).reshape(2, 3, 4)\n",
    "t_x = torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff4f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd55fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b84afede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/td31czvd29qc_qk6bh070n680000gn/T/ipykernel_37478/3570308358.py:1: UserWarning: Explicitly requested dtype int64 requested in argmax is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  jax.lax.argmax(j_x,axis=0,index_dtype=jnp.int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.argmax(j_x, axis=0, index_dtype=jnp.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c819e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.argmax.default(t_x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92094402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66b9b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  6,  8, 10],\n",
       "        [12, 15, 18, 21]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [28, 30, 32, 34],\n",
       "        [48, 51, 54, 57]]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.cumsum(j_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4cf8dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([11, 23], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.reduce_max(\n",
    "    j_x,\n",
    "    axes=(\n",
    "        2,\n",
    "        1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c67cc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c5e5008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 23])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.amax(t_x, dim=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ffa5a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 23])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.amax.default(\n",
    "    t_x,\n",
    "    dim=(\n",
    "        2,\n",
    "        1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a9ca288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([15, 31], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.reduce_or(j_x, axes=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06d1d288",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logical reduction requires operand dtype bool or int, got float32.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m j_x_1 = jnp.array([[\u001b[32m1.4\u001b[39m,\u001b[32m2.4\u001b[39m,\u001b[32m1.4\u001b[39m],[\u001b[32m1.1\u001b[39m,\u001b[32m2.3\u001b[39m,\u001b[32m2.5\u001b[39m]])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_or\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_x_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:3213\u001b[39m, in \u001b[36mreduce_or\u001b[39m\u001b[34m(operand, axes)\u001b[39m\n\u001b[32m   3193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce_or\u001b[39m(operand: ArrayLike, axes: Sequence[\u001b[38;5;28mint\u001b[39m]) -> Array:\n\u001b[32m   3194\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Compute the bitwise OR of elements over one or more array axes.\u001b[39;00m\n\u001b[32m   3195\u001b[39m \n\u001b[32m   3196\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3211\u001b[39m \u001b[33;03m      :func:`jax.lax.reduce_min`, :func:`jax.lax.reduce_and`, :func:`jax.lax.reduce_xor`.\u001b[39;00m\n\u001b[32m   3212\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3213\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce_or_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:632\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    631\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:648\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    646\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    650\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:660\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_current_trace(trace):\n\u001b[32m    659\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_lojax(*args, **params)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m trace.process_primitive(\u001b[38;5;28mself\u001b[39m, args, params)  \u001b[38;5;66;03m# may raise lojax error\u001b[39;00m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt apply typeof to args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:1205\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1203\u001b[39m args = \u001b[38;5;28mmap\u001b[39m(full_lower, args)\n\u001b[32m   1204\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:91\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     89\u001b[39m prev = config.disable_jit.swap_local(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m   config.disable_jit.set_local(prev)\n",
      "    \u001b[31m[... skipping hidden 16 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:7843\u001b[39m, in \u001b[36m_reduce_logical_shape_rule\u001b[39m\u001b[34m(operand, axes)\u001b[39m\n\u001b[32m   7841\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reduce_logical_shape_rule\u001b[39m(operand, *, axes):\n\u001b[32m   7842\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m operand.dtype != np.bool_ \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.issubdtype(operand.dtype, np.integer):\n\u001b[32m-> \u001b[39m\u001b[32m7843\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlogical reduction requires operand dtype bool or int, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperand.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7844\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(np.delete(operand.shape, axes))\n",
      "\u001b[31mTypeError\u001b[39m: logical reduction requires operand dtype bool or int, got float32."
     ]
    }
   ],
   "source": [
    "j_x_1 = jnp.array([[1.4, 2.4, 1.4], [1.1, 2.3, 2.5]])\n",
    "jax.lax.reduce_or(j_x_1, axes=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19acd0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([[[ 3],\n",
       "         [ 7],\n",
       "         [11]],\n",
       " \n",
       "        [[15],\n",
       "         [19],\n",
       "         [23]]], dtype=int32),\n",
       " Array([[[3],\n",
       "         [3],\n",
       "         [3]],\n",
       " \n",
       "        [[3],\n",
       "         [3],\n",
       "         [3]]], dtype=int32)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.top_k(j_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7511d483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[[ 3],\n",
       "         [ 7],\n",
       "         [11]],\n",
       "\n",
       "        [[15],\n",
       "         [19],\n",
       "         [23]]]),\n",
       "indices=tensor([[[3],\n",
       "         [3],\n",
       "         [3]],\n",
       "\n",
       "        [[3],\n",
       "         [3],\n",
       "         [3]]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(t_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8c44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuel-jax (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
