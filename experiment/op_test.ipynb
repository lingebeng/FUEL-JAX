{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import jax.lax as lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sanity_is_finite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lax.is_finite(jnp.array([1, 2, 3, 4], dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sort_mapping_case",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.lax.sort mapping check passed\n"
     ]
    }
   ],
   "source": [
    "# jax.lax.sort vs torch.ops.aten.sort.default\n",
    "x_np = np.array([[3.0, -1.0, 2.5, 2.5], [0.0, -4.2, 8.1, 1.1]], dtype=np.float32)\n",
    "x_jax = jnp.array(x_np)\n",
    "x_torch = torch.tensor(x_np)\n",
    "\n",
    "# Test ascending sort on last dimension\n",
    "jax_sorted_last = np.array(lax.sort(x_jax, dimension=-1))\n",
    "torch_sorted_last, _ = torch.ops.aten.sort.default(x_torch, dim=-1, descending=False)\n",
    "np.testing.assert_allclose(\n",
    "    jax_sorted_last, torch_sorted_last.numpy(), rtol=0.0, atol=0.0\n",
    ")\n",
    "\n",
    "# Test sort on a non-last dimension\n",
    "jax_sorted_dim0 = np.array(lax.sort(x_jax, dimension=0))\n",
    "torch_sorted_dim0, _ = torch.ops.aten.sort.default(x_torch, dim=0, descending=False)\n",
    "np.testing.assert_allclose(\n",
    "    jax_sorted_dim0, torch_sorted_dim0.numpy(), rtol=0.0, atol=0.0\n",
    ")\n",
    "\n",
    "print(\"jax.lax.sort mapping check passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "scatter_mul_mapping_case",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.lax.scatter_mul mapping check passed\n"
     ]
    }
   ],
   "source": [
    "# jax.lax.scatter_mul vs torch.ops.aten.scatter_reduce_.two (reduce='prod')\n",
    "operand_np = np.array([2.0, 3.0, 4.0, 5.0], dtype=np.float32)\n",
    "indices_np = np.array([[1], [3], [1]], dtype=np.int32)\n",
    "updates_np = np.array([10.0, 2.0, 0.5], dtype=np.float32)\n",
    "\n",
    "operand_jax = jnp.array(operand_np)\n",
    "indices_jax = jnp.array(indices_np)\n",
    "updates_jax = jnp.array(updates_np)\n",
    "dnums = lax.ScatterDimensionNumbers(\n",
    "    update_window_dims=(),\n",
    "    inserted_window_dims=(0,),\n",
    "    scatter_dims_to_operand_dims=(0,),\n",
    ")\n",
    "out_jax = np.array(lax.scatter_mul(operand_jax, indices_jax, updates_jax, dnums))\n",
    "\n",
    "operand_torch = torch.tensor(operand_np)\n",
    "index_torch = torch.tensor(indices_np.squeeze(-1), dtype=torch.long)\n",
    "updates_torch = torch.tensor(updates_np)\n",
    "out_torch = operand_torch.clone()\n",
    "torch.ops.aten.scatter_reduce_.two(\n",
    "    out_torch, 0, index_torch, updates_torch, \"prod\", include_self=True\n",
    ")\n",
    "\n",
    "np.testing.assert_allclose(out_jax, out_torch.numpy(), rtol=0.0, atol=0.0)\n",
    "print(\"jax.lax.scatter_mul mapping check passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a63dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: [-5.  -1.   0.5  3.  10. ]\n",
      "输出: [-2.  -1.   0.5  2.   2. ]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "\n",
    "# 1. 准备数据\n",
    "x = jnp.array([-5.0, -1.0, 0.5, 3.0, 10.0])\n",
    "\n",
    "# 2. 调用 lax.clamp\n",
    "# 语义：把 x 限制在 [-2.0, 2.0] 之间\n",
    "# 参数顺序：(最小值, 输入数据, 最大值)\n",
    "result = lax.clamp(-2.0, x, 2.0)\n",
    "\n",
    "print(f\"输入: {x}\")\n",
    "print(f\"输出: {result}\")\n",
    "\n",
    "# 输出预期:\n",
    "# [-2.0, -1.0, 0.5, 2.0, 2.0]\n",
    "# (-5 变成了 -2, 10 变成了 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997bef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.lax.lax.sort(operand: 'Array | Sequence[Array]', dimension: 'int' = -1, is_stable: 'bool' = True, num_keys: 'int' = 1) -> 'Array | tuple[Array, ...]'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.lax.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fd6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70bb43f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5]), tensor([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "torch.ops.aten.sort.default(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f50052d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.lax.lax.dot_general(lhs: 'ArrayLike', rhs: 'ArrayLike', dimension_numbers: 'DotDimensionNumbers', precision: 'PrecisionLike' = None, preferred_element_type: 'DTypeLike | None' = None, *, out_sharding=None) -> 'Array'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.dot_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c406ea62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.lax.lax.batch_matmul(lhs: 'Array', rhs: 'Array', precision: 'PrecisionLike' = None) -> 'Array'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.dot\n",
    "jax.lax.dot_general\n",
    "jax.lax.dot_general_p\n",
    "jax.lax.batch_matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26df9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.matmul>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c38c10e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PjitFunction of <function matmul at 0x133cf1120>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "449efae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax.lax.cbrt(x: 'ArrayLike', accuracy=None) -> 'Array'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.cbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25329091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0., 1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.iota(jnp.float32, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e00e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.lax.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a43c3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_x = jnp.arange(24).reshape(2, 3, 4)\n",
    "t_x = torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff4f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd55fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b84afede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/td31czvd29qc_qk6bh070n680000gn/T/ipykernel_37478/3570308358.py:1: UserWarning: Explicitly requested dtype int64 requested in argmax is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  jax.lax.argmax(j_x,axis=0,index_dtype=jnp.int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.argmax(j_x, axis=0, index_dtype=jnp.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c819e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.argmax.default(t_x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92094402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66b9b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  6,  8, 10],\n",
       "        [12, 15, 18, 21]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [28, 30, 32, 34],\n",
       "        [48, 51, 54, 57]]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.cumsum(j_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4cf8dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([11, 23], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.reduce_max(\n",
    "    j_x,\n",
    "    axes=(\n",
    "        2,\n",
    "        1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c67cc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c5e5008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 23])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.amax(t_x, dim=(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ffa5a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 23])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.amax.default(\n",
    "    t_x,\n",
    "    dim=(\n",
    "        2,\n",
    "        1,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a9ca288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([15, 31], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.reduce_or(j_x, axes=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06d1d288",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logical reduction requires operand dtype bool or int, got float32.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m j_x_1 = jnp.array([[\u001b[32m1.4\u001b[39m,\u001b[32m2.4\u001b[39m,\u001b[32m1.4\u001b[39m],[\u001b[32m1.1\u001b[39m,\u001b[32m2.3\u001b[39m,\u001b[32m2.5\u001b[39m]])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce_or\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_x_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:3213\u001b[39m, in \u001b[36mreduce_or\u001b[39m\u001b[34m(operand, axes)\u001b[39m\n\u001b[32m   3193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce_or\u001b[39m(operand: ArrayLike, axes: Sequence[\u001b[38;5;28mint\u001b[39m]) -> Array:\n\u001b[32m   3194\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Compute the bitwise OR of elements over one or more array axes.\u001b[39;00m\n\u001b[32m   3195\u001b[39m \n\u001b[32m   3196\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3211\u001b[39m \u001b[33;03m      :func:`jax.lax.reduce_min`, :func:`jax.lax.reduce_and`, :func:`jax.lax.reduce_xor`.\u001b[39;00m\n\u001b[32m   3212\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3213\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce_or_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:632\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    631\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:648\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    646\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    650\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:660\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_current_trace(trace):\n\u001b[32m    659\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_lojax(*args, **params)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m trace.process_primitive(\u001b[38;5;28mself\u001b[39m, args, params)  \u001b[38;5;66;03m# may raise lojax error\u001b[39;00m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt apply typeof to args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/core.py:1205\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1203\u001b[39m args = \u001b[38;5;28mmap\u001b[39m(full_lower, args)\n\u001b[32m   1204\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:91\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     89\u001b[39m prev = config.disable_jit.swap_local(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m   config.disable_jit.set_local(prev)\n",
      "    \u001b[31m[... skipping hidden 16 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:7843\u001b[39m, in \u001b[36m_reduce_logical_shape_rule\u001b[39m\u001b[34m(operand, axes)\u001b[39m\n\u001b[32m   7841\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_reduce_logical_shape_rule\u001b[39m(operand, *, axes):\n\u001b[32m   7842\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m operand.dtype != np.bool_ \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.issubdtype(operand.dtype, np.integer):\n\u001b[32m-> \u001b[39m\u001b[32m7843\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlogical reduction requires operand dtype bool or int, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperand.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7844\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(np.delete(operand.shape, axes))\n",
      "\u001b[31mTypeError\u001b[39m: logical reduction requires operand dtype bool or int, got float32."
     ]
    }
   ],
   "source": [
    "j_x_1 = jnp.array([[1.4, 2.4, 1.4], [1.1, 2.3, 2.5]])\n",
    "jax.lax.reduce_or(j_x_1, axes=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19acd0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(jax.lax.top_k(j_x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7511d483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[[ 3],\n",
       "         [ 7],\n",
       "         [11]],\n",
       "\n",
       "        [[15],\n",
       "         [19],\n",
       "         [23]]]),\n",
       "indices=tensor([[[3],\n",
       "         [3],\n",
       "         [3]],\n",
       "\n",
       "        [[3],\n",
       "         [3],\n",
       "         [3]]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(t_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43d8c44e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (2, 3, 4), (2, 4, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_x\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/linalg.py:102\u001b[39m, in \u001b[36mcholesky\u001b[39m\u001b[34m(x, symmetrize_input)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Cholesky decomposition.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[33;03mComputes the Cholesky decomposition\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m \u001b[33;03m  full of NaNs. The behavior on failure may change in the future.\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m symmetrize_input:\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m   x = \u001b[43msymmetrize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _tril(cholesky_p.bind(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/linalg.py:2703\u001b[39m, in \u001b[36msymmetrize\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2703\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msymmetrize\u001b[39m(x: Array) -> Array: \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_H\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) / \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:609\u001b[39m, in \u001b[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    607\u001b[39m args = (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/numpy/ufunc_api.py:182\u001b[39m, in \u001b[36mufunc.__call__\u001b[39m\u001b[34m(self, out, where, *args)\u001b[39m\n\u001b[32m    180\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhere argument of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    181\u001b[39m call = \u001b[38;5;28mself\u001b[39m.__static_props[\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_vectorized\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 4 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/numpy/ufuncs.py:1238\u001b[39m, in \u001b[36madd\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.dtype == \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   1237\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m lax.bitwise_or(x, y)\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m out = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m jnp_error._set_error_if_nan(out)\n\u001b[32m   1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "    \u001b[31m[... skipping hidden 13 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ModelTransfer-TDD/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:130\u001b[39m, in \u001b[36m_try_broadcast_shapes\u001b[39m\u001b[34m(name, *shapes)\u001b[39m\n\u001b[32m    128\u001b[39m       result_shape.append(non_1s[\u001b[32m0\u001b[39m])\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m got incompatible shapes for broadcasting: \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    131\u001b[39m                       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[31mTypeError\u001b[39m: add got incompatible shapes for broadcasting: (2, 3, 4), (2, 4, 3)."
     ]
    }
   ],
   "source": [
    "jax.lax.linalg.cholesky(j_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17b91469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spd_matrix_numpy(n, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    生成一个 (n, n) 的对称正定矩阵\n",
    "    \"\"\"\n",
    "    # 1. 生成随机矩阵 X\n",
    "    # 使用 randn (正态分布) 或 rand (均匀分布) 都可以\n",
    "    X = np.random.randn(n, n)\n",
    "\n",
    "    # 2. 构造 Gram 矩阵: A = X @ X.T\n",
    "    # 这一步保证了 A 是对称半正定\n",
    "    A = np.dot(X, X.T)  # 或者 X @ X.T\n",
    "\n",
    "    # 3. 添加对角线抖动 (Diagonal Jitter)\n",
    "    # 这一步保证了 A 是严格正定 (特征值全部 > 0)\n",
    "    # 没有这一步，np.linalg.cholesky 经常会因为浮点误差报错\n",
    "    A += np.eye(n) * epsilon\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b4eaa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 8.85925   , -7.3990436 , -0.7349571 , -0.51188713, -6.956379  ,\n",
       "         2.5022967 ,  1.2976339 ,  4.183757  , -1.8656918 ,  1.6225336 ],\n",
       "       [-7.3990436 , 10.948375  ,  1.2316022 ,  0.32384533,  7.109779  ,\n",
       "        -3.7424417 , -2.3546789 , -0.29677695,  4.271814  , -2.8162992 ],\n",
       "       [-0.7349571 ,  1.2316022 ,  9.723164  , -3.9999845 ,  2.070975  ,\n",
       "        -1.4916484 ,  2.9989853 ,  3.0603955 , -1.8261552 , -0.934536  ],\n",
       "       [-0.51188713,  0.32384533, -3.9999845 , 14.525578  , -0.14456035,\n",
       "        -0.38652018, -3.403186  , -4.4579296 , -1.9781421 ,  5.458454  ],\n",
       "       [-6.956379  ,  7.109779  ,  2.070975  , -0.14456035, 10.807528  ,\n",
       "        -3.0774956 , -2.165046  , -5.1064677 ,  2.6150033 , -1.2000664 ],\n",
       "       [ 2.5022967 , -3.7424417 , -1.4916484 , -0.38652018, -3.0774956 ,\n",
       "        11.761526  ,  5.7378354 ,  1.0636797 ,  0.02985495,  1.5216056 ],\n",
       "       [ 1.2976339 , -2.3546789 ,  2.9989853 , -3.403186  , -2.165046  ,\n",
       "         5.7378354 ,  8.157122  ,  5.1486387 , -1.0024357 ,  1.6481473 ],\n",
       "       [ 4.183757  , -0.29677695,  3.0603955 , -4.4579296 , -5.1064677 ,\n",
       "         1.0636797 ,  5.1486387 , 10.888619  ,  0.8757573 , -0.5312716 ],\n",
       "       [-1.8656918 ,  4.271814  , -1.8261552 , -1.9781421 ,  2.6150033 ,\n",
       "         0.02985495, -1.0024357 ,  0.8757573 ,  4.5830016 , -1.2150149 ],\n",
       "       [ 1.6225336 , -2.8162992 , -0.934536  ,  5.458454  , -1.2000664 ,\n",
       "         1.5216056 ,  1.6481473 , -0.5312716 , -1.2150149 ,  5.008908  ]],      dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_x = jnp.array(make_spd_matrix_numpy(10))\n",
    "j_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5588c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 2.9764493 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-2.4858625 ,  2.1837726 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.24692412,  0.28289703,  3.0955067 ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.17197913, -0.04747342, -1.3015705 ,  3.5776613 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-2.33714   ,  0.59528637,  0.42819294,  0.01092444,  2.1925943 ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.8406986 , -0.7567549 , -0.34565455, -0.20341699, -0.23349062,\n",
       "         3.2041695 ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.4359671 , -0.58198583,  1.0567827 , -0.5535349 , -0.56834114,\n",
       "         1.5763456 ,  1.8431709 ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 1.4056201 ,  1.464164  ,  0.9669723 , -0.8072593 , -1.4130136 ,\n",
       "         0.25906646,  1.4690877 ,  0.9800156 ,  0.        ,  0.        ],\n",
       "       [-0.62681794,  1.2426343 , -0.7535016 , -0.8406847 ,  0.3384789 ,\n",
       "         0.3572721 , -0.02487117,  0.4179784 ,  0.9766828 ,  0.        ],\n",
       "       [ 0.5451239 , -0.66911554, -0.19726688,  1.4712634 ,  0.24659158,\n",
       "         0.26391703,  0.95925075, -0.06992663,  0.9437061 ,  0.33824405]],      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_jax = jax.lax.linalg.cholesky(j_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "610b7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = torch.from_numpy(np.array(j_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fe7a890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9764,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-2.4859,  2.1838,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-0.2469,  0.2829,  3.0955,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-0.1720, -0.0475, -1.3016,  3.5777,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-2.3371,  0.5953,  0.4282,  0.0109,  2.1926,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.8407, -0.7568, -0.3457, -0.2034, -0.2335,  3.2042,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.4360, -0.5820,  1.0568, -0.5535, -0.5683,  1.5763,  1.8432,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 1.4056,  1.4642,  0.9670, -0.8073, -1.4130,  0.2591,  1.4691,  0.9800,\n",
       "          0.0000,  0.0000],\n",
       "        [-0.6268,  1.2426, -0.7535, -0.8407,  0.3385,  0.3573, -0.0249,  0.4180,\n",
       "          0.9767,  0.0000],\n",
       "        [ 0.5451, -0.6691, -0.1973,  1.4713,  0.2466,  0.2639,  0.9593, -0.0699,\n",
       "          0.9437,  0.3382]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.linalg_cholesky.default(t_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7224297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuel-jax (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
