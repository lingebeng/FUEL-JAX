jax,pytorch,type,remark,torch 精度支持
jax.lax.abs,torch.abs,elementwise,绝对值,FP32、BF16、FP8_E4M3、FP8_E5M2
jax.lax.acos,torch.acos,elementwise,反余弦,FP32、BF16
jax.lax.acosh,torch.acosh,elementwise,反双曲余弦,
jax.lax.add,torch.add,elementwise,加法,
jax.lax.asin,torch.asin,elementwise,反正弦,
jax.lax.asinh,torch.asinh,elementwise,反双曲正弦,
jax.lax.atan,torch.atan,elementwise,反正切,
jax.lax.atan2,torch.atan2,elementwise,双参数反正切,
jax.lax.atanh,torch.atanh,elementwise,反双曲正切,
jax.lax.bessel_i0e,torch.special.i0e,elementwise,第一类修正贝塞尔函数 I0e,
jax.lax.bessel_i1e,torch.special.i1e,elementwise,第一类修正贝塞尔函数 I1e,
jax.lax.betainc,torch.special.betainc,elementwise,不完全贝塔函数,
jax.lax.bitcast_convert_type,torch.view,elementwise,位级类型重解释,
jax.lax.cbrt,"torch.pow(x,1/3)",elementwise,立方根,
jax.lax.ceil,torch.ceil,elementwise,向上取整,
jax.lax.clamp,torch.clamp,elementwise,区间截断,
jax.lax.complex,torch.complex,elementwise,复数构造,
jax.lax.conj,torch.conj,elementwise,复共轭,
jax.lax.cos,torch.cos,elementwise,余弦,
jax.lax.cosh,torch.cosh,elementwise,双曲余弦,
jax.lax.digamma,torch.digamma,elementwise,双伽玛函数,
jax.lax.div,torch.div,elementwise,除法,
jax.lax.erf,torch.erf,elementwise,误差函数,
jax.lax.erfc,torch.erfc,elementwise,互补误差函数,
jax.lax.erf_inv,torch.erfinv,elementwise,误差函数反函数,
jax.lax.exp,torch.exp,elementwise,指数,
jax.lax.exp2,torch.exp2,elementwise,以 2 为底的指数,
jax.lax.expm1,torch.expm1,elementwise,e^x - 1,
jax.lax.floor,torch.floor,elementwise,向下取整,
jax.lax.integer_pow,torch.pow,elementwise,整数幂,
jax.lax.is_finite,torch.isfinite,elementwise,是否为有限值,
jax.lax.lgamma,torch.lgamma,elementwise,伽玛函数对数,
jax.lax.log,torch.log,elementwise,自然对数,
jax.lax.log1p,torch.log1p,elementwise,ln(1+x),
jax.lax.logistic,torch.sigmoid,elementwise,Sigmoid/逻辑函数,
jax.lax.lt,torch.lt,elementwise,小于,
jax.lax.max,torch.maximum,elementwise,逐元素最大值,
jax.lax.min,torch.minimum,elementwise,逐元素最小值,
jax.lax.mul,torch.mul,elementwise,乘法,
jax.lax.neg,torch.neg,elementwise,取负,
jax.lax.nextafter,torch.nextafter,elementwise,朝向下一个可表示浮点,
jax.lax.polygamma,torch.special.polygamma,elementwise,多伽玛函数,
jax.lax.pow,torch.pow,elementwise,幂,
jax.lax.reciprocal,torch.reciprocal,elementwise,倒数,
jax.lax.rem,torch.remainder,elementwise,余数,
jax.lax.round,torch.round,elementwise,四舍五入,
jax.lax.rsqrt,torch.rsqrt,elementwise,反平方根,
jax.lax.sign,torch.sign,elementwise,符号,
jax.lax.sin,torch.sin,elementwise,正弦,
jax.lax.sinh,torch.sinh,elementwise,双曲正弦,
jax.lax.sqrt,torch.sqrt,elementwise,平方根,
jax.lax.square,torch.square,elementwise,平方,
jax.lax.sub,torch.sub,elementwise,减法,
jax.lax.tan,torch.tan,elementwise,正切,
jax.lax.tanh,torch.tanh,elementwise,双曲正切,
jax.lax.zeta,torch.special.zeta,elementwise,黎曼ζ函数,
jax.lax.broadcast,torch.broadcast_to,array,广播,
jax.lax.broadcast_in_dim,torch.broadcast_to,array,按维度广播,
jax.lax.collapse,torch.flatten,array,维度折叠,
jax.lax.concatenate,torch.cat,array,拼接,
jax.lax.convert_element_type,torch.Tensor.to,array,元素类型转换,
jax.lax.dynamic_index_in_dim,torch.index_select,array,动态单维索引,
jax.lax.dynamic_slice_in_dim,torch.narrow,array,动态单维切片,
jax.lax.expand_dims,torch.unsqueeze,array,增加维度,
jax.lax.full,torch.full,array,常量填充,
jax.lax.full_like,torch.full_like,array,按形状常量填充,
jax.lax.index_in_dim,torch.index_select,array,单维索引,
jax.lax.iota,torch.arange,array,序列索引,
jax.lax.pad,torch.nn.functional.pad,array,填充,
jax.lax.reshape,torch.reshape,array,重塑,
jax.lax.rev,torch.flip,array,反转,
jax.lax.slice_in_dim,torch.narrow,array,单维切片,
jax.lax.split,torch.split,array,分割,
jax.lax.squeeze,torch.squeeze,array,压缩维度,
jax.lax.tile,torch.tile,array,平铺重复,
jax.lax.transpose,torch.permute,array,转置/置换,
jax.lax.approx_max_k,torch.topk,reduction,近似 Top-K 最大值,
jax.lax.approx_min_k,torch.topk,reduction,近似 Top-K 最小值,
jax.lax.argmax,torch.argmax,reduction,最大值索引,
jax.lax.argmin,torch.argmin,reduction,最小值索引,
jax.lax.reduce_and,torch.all,reduction,逻辑与归约,
jax.lax.reduce_max,torch.amax,reduction,最大值归约,
jax.lax.reduce_min,torch.amin,reduction,最小值归约,
jax.lax.reduce_or,torch.any,reduction,逻辑或归约,
jax.lax.reduce_prod,torch.prod,reduction,乘积归约,
jax.lax.cumlogsumexp,torch.logcumsumexp,reduction,累积 log-sum-exp,
jax.lax.cummax,torch.cummax,reduction,累积最大值,
jax.lax.cummin,torch.cummin,reduction,累积最小值,
jax.lax.cumprod,torch.cumprod,reduction,累积乘积,
jax.lax.cumsum,torch.cumsum,reduction,累积和,
jax.lax.top_k,torch.topk,reduction,Top-K,
jax.lax.cholesky,torch.linalg.cholesky,linalg,Cholesky 分解,
jax.lax.eig,torch.linalg.eig,linalg,特征分解,
jax.lax.eigh,torch.linalg.eigh,linalg,对称/厄米特特征分解,
jax.lax.householder_product,torch.linalg.householder_product,linalg,Householder 乘积,
jax.lax.lu,torch.linalg.lu,linalg,LU 分解,
jax.lax.qr,torch.linalg.qr,linalg,QR 分解,
jax.lax.svd,torch.linalg.svd,linalg,奇异值分解,
jax.lax.triangular_solve,torch.linalg.solve_triangular,linalg,三角矩阵求解,
jax.lax.batch_matmul,torch.bmm,other,批量矩阵乘,
jax.lax.conv,torch.nn.functional.conv2d,other,卷积,
jax.lax.conv_general_dilated,torch.nn.functional.conv2d,other,通用空洞卷积,
jax.lax.conv_general_dilated_patches,torch.nn.functional.unfold,other,提取卷积补丁,
jax.lax.conv_transpose,torch.nn.functional.conv_transpose2d,other,转置卷积,
jax.lax.conv_with_general_padding,torch.nn.functional.conv2d,other,通用填充卷积,
jax.lax.dot,torch.matmul,other,点积/矩阵乘,
jax.lax.dot_general,torch.einsum,other,通用点积,
jax.lax.empty,torch.empty,other,空张量,
jax.lax.fft,torch.fft.fft,other,快速傅里叶变换,
jax.lax.gather,torch.gather,other,收集/索引,
jax.lax.index_take,torch.index_select,other,索引提取,
jax.lax.rng_bit_generator,torch.Generator,other,随机比特生成器,
jax.lax.rng_uniform,torch.rand,other,均匀随机数,
jax.lax.scatter,torch.Tensor.scatter_,other,散射写入,
jax.lax.scatter_add,torch.Tensor.scatter_add_,other,散射加,
jax.lax.scatter_max,torch.Tensor.scatter_reduce_,other,散射最大,
jax.lax.scatter_min,torch.Tensor.scatter_reduce_,other,散射最小,
jax.lax.scatter_mul,torch.Tensor.scatter_reduce_,other,散射乘,
jax.lax.sort,torch.sort,other,排序,
jax.lax.sort_key_val,torch.sort,other,键值排序,
